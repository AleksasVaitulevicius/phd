{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd263db-6cfd-4668-b228-e64ff1689034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "from skfda import FDataGrid\n",
    "from skfda.representation.basis import BSpline\n",
    "from skfda.preprocessing.smoothing import BasisSmoother\n",
    "from skfda.preprocessing.registration import ElasticRegistration, landmark_registration\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skfda.exploratory.depth import IntegratedDepth, ModifiedBandDepth\n",
    "\n",
    "from cycler import cycler\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import (\n",
    "\tprecision_score, recall_score, f1_score, balanced_accuracy_score, roc_curve, confusion_matrix\n",
    ")\n",
    "\n",
    "\n",
    "agg_columns = ['patient_id', 'slice_id', 'img_type']\n",
    "\n",
    "n_basis=18\n",
    "order=4\n",
    "\n",
    "prc_rm=0.05\n",
    "n_points=111\n",
    "\n",
    "basis = BSpline(domain_range=(0, 1), n_basis=n_basis, order=order)\n",
    "smoother = BasisSmoother(basis=basis, return_basis=True, method='svd')\n",
    "\n",
    "registration = ElasticRegistration()\n",
    "ID = IntegratedDepth()\n",
    "MBD = ModifiedBandDepth()\n",
    "\n",
    "\n",
    "def get_model():\n",
    "\treturn {\n",
    "\t\t'svm': SVC(class_weight='balanced', probability=True),\n",
    "\t\t'rf': RandomForestClassifier(class_weight='balanced', n_jobs=4),\n",
    "\t\t'xgb': xgb.XGBClassifier(tree_method='gpu_hist', eval_metric='logloss', use_label_encoder=False),\n",
    "\t}[MODEL]\n",
    "\n",
    "\n",
    "def cut_ends(bsplined, order=0, prc_rm_start=prc_rm, prc_rm_end=prc_rm, n_points=n_points):\n",
    "\tbsplined_grid = bsplined.derivative(order=order).to_grid(np.linspace(0, 1, n_points))\n",
    "\treturn FDataGrid(\n",
    "\t\tdata_matrix=bsplined_grid.data_matrix[\n",
    "\t\t\t..., int(n_points * prc_rm_start): int(n_points * (1 - prc_rm_end)), 0\n",
    "\t\t],\n",
    "\t\tgrid_points=bsplined_grid.grid_points[0][\n",
    "\t\t\tint(n_points * prc_rm_start): int(n_points * (1 - prc_rm_end))\n",
    "\t\t]\n",
    "\t)\n",
    "\n",
    "\n",
    "def get_landmark_registration(bsplined, order=0):\n",
    "\tbsplined_grid = cut_ends(bsplined, order)\n",
    "\tlandmark_indexes = cut_ends(bsplined, order, prc_rm_end=0.5).data_matrix.argmax(axis=1)\n",
    "\tgrid_points = bsplined_grid.grid_points[0]\n",
    "\tlandmarks = [grid_points[index] for index in np.concatenate(landmark_indexes)]\n",
    "\treturn landmark_registration(bsplined_grid, landmarks)\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cd2771-70c8-4a2f-8dff-a5e395b41688",
   "metadata": {},
   "source": [
    "## Print curves of each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698233ce-dce3-452f-add3-7b4fa733aaa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segmentation_id = 4\n",
    "# patients = [3, 6, 7, 29, 66, 76, 108, 119, 133, 140]\n",
    "patients = [2, 15, 28, 32, 35, 39, 40, 41, 45, 50, 52, 64, 66]\n",
    "bspline_levels = ['patient_id', 'slice_id']\n",
    "min_n_curves = 5\n",
    "\n",
    "dataset = (\n",
    "\tpd.read_csv(\n",
    "\t\tf'./segmentations/segmentation-{segmentation_id}.csv',\n",
    "\t\tdtype={\n",
    "\t\t\t'img_type': int,\n",
    "\t\t\t'patient_id': int,\n",
    "\t\t\t'cycle_id': int,\n",
    "\t\t\t'slice_id': int,\n",
    "\t\t\t'label': bool,\n",
    "\t\t\t'mask_int_mean': float,\n",
    "\t\t\t'segment': int,\n",
    "\t\t},\n",
    "\t)\n",
    "\t\t.drop_duplicates()\n",
    "\t\t.sort_values(agg_columns + ['cycle_id'])\n",
    ")\n",
    "dataset = dataset[dataset.patient_id.apply(lambda x: x in patients)]\n",
    "dataset = dataset.merge(dataset.query('label')[bspline_levels].drop_duplicates())\n",
    "ts = (\n",
    "\tdataset[bspline_levels + ['cycle_id']].drop_duplicates()\n",
    "\t\t.groupby(bspline_levels).cycle_id.count()\n",
    "\t\t.apply(lambda x: np.linspace(0, 1, int(x)))\n",
    "\t\t.reset_index()\n",
    ")\n",
    "\n",
    "dataset = dataset.groupby(agg_columns + ['label']).mask_int_mean.apply(list).reset_index()\n",
    "labels = dataset.groupby(bspline_levels).label.apply(list).reset_index()\n",
    "dataset = dataset.groupby(bspline_levels).mask_int_mean.apply(list).reset_index().merge(ts)\n",
    "dataset = dataset[dataset.mask_int_mean.apply(lambda x: len(x) >= min_n_curves)]\n",
    "dataset['bsplined'] = dataset.apply(\n",
    "\tlambda x: smoother.fit_transform(\n",
    "\t\tFDataGrid(data_matrix=x['mask_int_mean'], grid_points=x['cycle_id'])\n",
    "\t),\n",
    "\taxis='columns',\n",
    ")\n",
    "# dataset['bsplined'] = dataset.bsplined.apply(get_landmark_registration, order=1)\n",
    "dataset['bsplined'] = dataset.bsplined.apply(cut_ends, order=1)\n",
    "dataset = dataset[bspline_levels + ['bsplined']]\n",
    "dataset = dataset.merge(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f21f7-e1e2-4d36-a3a8-74c0b0a8fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_patient(row, segmentation_id):\n",
    "\tcolors = ['red' if x else 'green' for x in row['label']]\n",
    "\talphas = [1 if x else 0.1 for x in row['label']]\n",
    "\tcolor_cycle = cycler(color=colors, alpha=alphas)\n",
    "\n",
    "\tfig = plt.figure(figsize=(11, 7))\n",
    "\tax = plt.axes(xlabel='t')\n",
    "\tax.set_prop_cycle(color_cycle)\n",
    "\trow['bsplined'].plot(fig=fig, ax=ax)\n",
    "\tname = f'./patient_plots/patient-{row[\"patient_id\"]}-segment-{segmentation_id}.png'\n",
    "\tif 'slice_id' in dataset.columns:\n",
    "\t\tname = f'./patient_slice_plots_unregistered/patient-{row[\"patient_id\"]}-slice{row[\"slice_id\"]}-segment-{segmentation_id}.png'\n",
    "\tplt.savefig(name, dpi=150)\n",
    "\tplt.close()\n",
    "\n",
    "\n",
    "x = dataset.apply(print_patient, segmentation_id=segmentation_id, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25df7041-f7b3-4337-9525-ab407df0adbc",
   "metadata": {},
   "source": [
    "## Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b3721d-3277-44f0-bf2b-e62ca14805f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = 'features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375acb31-1033-4f35-8c44-e8d696d6dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n_points = 100\n",
    "\n",
    "\n",
    "def get_descrete_points(fd_smooth):\n",
    "\tt_cut = np.linspace(\n",
    "\t\tstart=0,\n",
    "\t\tstop=fd_smooth.data_matrix.shape[1] - 1,\n",
    "\t\tnum=train_n_points, endpoint=True, dtype=int,\n",
    "\t)\n",
    "\treturn fd_smooth.data_matrix[:, t_cut, 0]\n",
    "\n",
    "\n",
    "def cart2pol(x, y):\n",
    "\trho = np.sqrt(x**2 + y**2)\n",
    "\tphi = np.arctan2(y, x)\n",
    "\treturn(rho, phi)\n",
    "\n",
    "\n",
    "segmentations = []\n",
    "\n",
    "for segmentation_id in range(0, 25):\n",
    "\tprint(segmentation_id)\n",
    "\tfile = f'./segmentations/segmentation-{segmentation_id}.csv'\n",
    "\tdataset = (\n",
    "\tpd.read_csv(\n",
    "\t\tfile,\n",
    "\t\tdtype={\n",
    "\t\t\t'img_type': int,\n",
    "\t\t\t'patient_id': int,\n",
    "\t\t\t'cycle_id': int,\n",
    "\t\t\t'slice_id': int,\n",
    "\t\t\t'label': bool,\n",
    "\t\t\t'mask_int_mean': float,\n",
    "\t\t\t'segment': int,\n",
    "\t\t},\n",
    "\t)\n",
    "\t.drop_duplicates()\n",
    "\t.sort_values(agg_columns + ['cycle_id'])\n",
    "\t)\n",
    "\tdataset = dataset.merge(dataset.query('label').patient_id.drop_duplicates())\n",
    "\t# dataset = dataset[dataset.patient_id.apply(lambda x: x not in [3, 6, 29, 86, 108, 119, 140])]\n",
    "\tdataset = dataset[dataset.patient_id.apply(lambda x: x in [2, 15, 28, 32, 35, 39, 40, 41, 45, 50, 52, 64, 66])]\n",
    "\tts = (\n",
    "\t\tdataset[['patient_id', 'cycle_id']].drop_duplicates()\n",
    "\t\t\t.groupby('patient_id').cycle_id.count()\n",
    "\t\t\t.apply(lambda x: np.linspace(0, 1, int(x)))\n",
    "\t\t\t.reset_index()\n",
    "\t)\n",
    "\n",
    "\tdataset = dataset.groupby(agg_columns + ['label']).mask_int_mean.apply(list).reset_index()\n",
    "\tbsplined = dataset.groupby('patient_id').mask_int_mean.apply(list).reset_index().merge(ts)\n",
    "\tbsplined = bsplined.apply(\n",
    "\t\tlambda x: smoother.fit_transform(\n",
    "\t\t\tFDataGrid(data_matrix=x['mask_int_mean'], grid_points=x['cycle_id'])\n",
    "\t\t),\n",
    "\t\taxis='columns',\n",
    "\t)\n",
    "\tprint('extracting features ...')\n",
    "\tregistered = [get_landmark_registration(fd_smooth, 1) for fd_smooth in bsplined]\n",
    "\tunregistered = [cut_ends(fd_smooth, 1) for fd_smooth in bsplined]\n",
    "\t\n",
    "\tdataset['unregistered_ids'] = np.concatenate(\n",
    "\t\t[ID(fd_smooth).reshape(-1, 1) for fd_smooth in unregistered]\n",
    "\t)\n",
    "\tdataset['unregistered_mbds'] = np.concatenate(\n",
    "\t\t[MBD(fd_smooth).reshape(-1, 1) for fd_smooth in unregistered]\n",
    "\t)\n",
    "\tdataset['unregistered_max_values'] = np.concatenate(\n",
    "\t\t[fd_smooth.data_matrix.max(axis=1).reshape(-1, 1) for fd_smooth in unregistered]\n",
    "\t)\n",
    "\t\n",
    "\tdataset['registered_ids'] = np.concatenate(\n",
    "\t\t[ID(fd_smooth).reshape(-1, 1) for fd_smooth in registered]\n",
    "\t)\n",
    "\tdataset['registered_mbds'] = np.concatenate(\n",
    "\t\t[MBD(fd_smooth).reshape(-1, 1) for fd_smooth in registered]\n",
    "\t)\n",
    "\tdataset['registered_max_values'] = np.concatenate(\n",
    "\t\t[fd_smooth.data_matrix.max(axis=1).reshape(-1, 1) for fd_smooth in registered]\n",
    "\t)\n",
    "\tregistered = [get_descrete_points(fd_smooth) for fd_smooth in registered]\n",
    "\tunregistered = [get_descrete_points(fd_smooth) for fd_smooth in unregistered]\n",
    "\n",
    "\tsegmentations += [\n",
    "\t\tdataset.drop('mask_int_mean', axis='columns')\n",
    "\t\t\t.assign(segmentation_id=segmentation_id)\n",
    "\t\t\t.join(\n",
    "\t\t\t\tpd.DataFrame(\n",
    "\t\t\t\t\tnp.concatenate(registered),\n",
    "\t\t\t\t\tcolumns=[f'registered_discrete_{i}' for i in range(100)],\n",
    "\t\t\t\t)\n",
    "\t\t\t)\n",
    "\t\t\t.join(\n",
    "\t\t\t\tpd.DataFrame(\n",
    "\t\t\t\t\tnp.concatenate(unregistered),\n",
    "\t\t\t\t\tcolumns=[f'unregistered_discrete_{i}' for i in range(100)],\n",
    "\t\t\t\t)\n",
    "\t\t\t)\n",
    "\t]\n",
    "\n",
    "dataset = pd.concat(segmentations)\n",
    "features = 'registered_discrete'\n",
    "registered_polar = [\n",
    "\t[cart2pol(0.01, x - y) for x, y in zip(row, np.concatenate([[0], row[:-1]]))]\n",
    "\tfor row in dataset[[f'{features}_{i}' for i in range(100)]].to_numpy()\n",
    "]\n",
    "registered_polar = (\n",
    "\tpd.DataFrame(\n",
    "\t\t[np.concatenate(row) for row in registered_polar],\n",
    "\t\tcolumns=np.concatenate(\n",
    "\t\t\t[\n",
    "\t\t\t\t[f'registered_polar_{i}_rho', f'registered_polar_{i}_phi']\n",
    "\t\t\t\tfor i in range(100)\n",
    "\t\t\t]\n",
    "\t\t)\n",
    "\t)\n",
    ")\n",
    "\n",
    "features = 'unregistered_discrete'\n",
    "unregistered_polar = [\n",
    "\t[cart2pol(0.01, x - y) for x, y in zip(row, np.concatenate([[0], row[:-1]]))]\n",
    "\tfor row in dataset[[f'{features}_{i}' for i in range(100)]].to_numpy()\n",
    "]\n",
    "unregistered_polar = (\n",
    "\tpd.DataFrame(\n",
    "\t\t[np.concatenate(row) for row in unregistered_polar],\n",
    "\t\tcolumns=np.concatenate(\n",
    "\t\t\t[\n",
    "\t\t\t\t[f'unregistered_polar_{i}_rho', f'unregistered_polar_{i}_phi']\n",
    "\t\t\t\tfor i in range(100)\n",
    "\t\t\t]\n",
    "\t\t)\n",
    "\t)\n",
    ")\n",
    "dataset.join(registered_polar).join(unregistered_polar).to_csv(FILE, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62670ab4-fffb-4b56-867e-b5ed1d4a2658",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learn on patients from generated features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef37c77-aaa3-478d-ab2d-ae328b2a58b3",
   "metadata": {},
   "source": [
    "#### With CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57db108-095b-4cdb-b279-31815ff0b93c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def specificity(y_true, y_pred, zero_division=0):\n",
    "\ttn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\tif tn+fp == 0 and zero_division:\n",
    "\t\treturn zero_division\n",
    "\treturn tn / (tn+fp)\n",
    "\n",
    "\n",
    "def train_eval(X, Y, model_producer, metrics=[f1_score]):\n",
    "\tmetric_results = [[] for _ in metrics]\n",
    "\tfor indices in k_folds.split(X, Y):\n",
    "\t\ttrain_indices, test_indices = indices\n",
    "\t\tX_train, X_test = X[train_indices], X[test_indices]\n",
    "\t\ty_train, y_test = Y[train_indices], Y[test_indices]\n",
    "\t\tneg_class_weight = (y_train == 1).sum() / len(y_train)\n",
    "\t\tweights = [\n",
    "\t\t\tneg_class_weight if label == 0 else 1 - neg_class_weight\n",
    "\t\t\tfor label in y_train\n",
    "\t\t]\n",
    "\t\tscaler = MinMaxScaler(feature_range=(0, 1), copy=False)\n",
    "\t\tscaler = scaler.fit(X_train)\n",
    "\t\tX_train = scaler.transform(X_train)\n",
    "\t\tX_test = scaler.transform(X_test)\n",
    "\t\tmodel = model_producer()\n",
    "\t\tmodel.fit(\n",
    "\t\t\tX_train, y_train,\n",
    "\t\t\tsample_weight=weights,\n",
    "\t\t\teval_set=[( X_train, y_train), ( X_test, y_test)],\n",
    "\t\t\teval_metric=\"auc\",\n",
    "\t\t\tverbose=False,\n",
    "\t\t)\n",
    "\n",
    "\t\tpred = model.predict(X_test)\n",
    "\t\tfor metric_result, metric in zip(metric_results, metrics):\n",
    "\t\t\tmetric_result.append(metric(y_test, pred))\n",
    "\treturn metric_results\n",
    "\n",
    "\n",
    "os.environ['HYPEROPT_FMIN_SEED'] = \"1\"\n",
    "k_folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "space = {\n",
    "\t'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "\t'gamma': hp.uniform('gamma', 0, 1),\n",
    "\t'reg_alpha' : hp.uniform('reg_alpha', 0, 1),\n",
    "\t'colsample_bytree' : hp.uniform('colsample_bytree', .4, .8),\n",
    "\t'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "\t'n_estimators': 180,\n",
    "\t'seed': 0\n",
    "}\n",
    "\n",
    "result = []\n",
    "dataset = pd.read_csv(FILE)\n",
    "features = 'unregistered_discrete'\n",
    "\n",
    "for patient, segmentation in (\n",
    "\tdataset[['patient_id', 'segmentation_id']]\n",
    "\t\t.drop_duplicates().to_records(index=False)\n",
    "):\n",
    "\tprint(f'patient - {patient}, segmentation - {segmentation}')\n",
    "\tdataset_group = dataset.query(\n",
    "\t\tf'segmentation_id == {segmentation} and patient_id == {patient}'\n",
    "\t)\n",
    "\ty = dataset_group.label.astype(int).to_numpy()\n",
    "\tX = dataset_group[[f'{features}_{i}' for i in range(100)]].to_numpy()\n",
    "\n",
    "\tdef objective(space):\n",
    "\t\tcreate_model = lambda: xgb.XGBClassifier(\n",
    "\t\t\tuse_label_encoder=False,\n",
    "\t\t\teval_metric='auc',\n",
    "\t\t\tn_estimators=space['n_estimators'],\n",
    "\t\t\tmax_depth=int(space['max_depth']),\n",
    "\t\t\tgamma=space['gamma'],\n",
    "\t\t\treg_alpha=space['reg_alpha'],\n",
    "\t\t\tmin_child_weight=space['min_child_weight'],\n",
    "\t\t\tcolsample_bytree=space['colsample_bytree'],\n",
    "\t\t)\n",
    "\t\tf1 = np.mean(train_eval(X, y, create_model)[0])\n",
    "\t\treturn {'loss': -f1, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "\ttrials = Trials()\n",
    "\n",
    "\tbest_hyperparams = fmin(\n",
    "\t\tfn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=trials\n",
    "\t)\n",
    "\n",
    "\tcreate_model = lambda: xgb.XGBClassifier(\n",
    "\t\tuse_label_encoder=False,\n",
    "\t\teval_metric='auc',\n",
    "\t\tn_estimators=space['n_estimators'],\n",
    "\t\tseed=space['seed'],\n",
    "\t\tmax_depth=int(best_hyperparams['max_depth']),\n",
    "\t\tgamma=best_hyperparams['gamma'],\n",
    "\t\treg_alpha=best_hyperparams['reg_alpha'],\n",
    "\t\tmin_child_weight=best_hyperparams['min_child_weight'],\n",
    "\t\tcolsample_bytree=best_hyperparams['colsample_bytree'],\n",
    "\t)\n",
    "\tmetrics = train_eval(\n",
    "\t\tX, y, create_model,\n",
    "\t\t[precision_score, recall_score, f1_score, balanced_accuracy_score, specificity]\n",
    "\t)\n",
    "\n",
    "\tmetrics = {\n",
    "\t\t'patient_id': patient,\n",
    "\t\t'segmentation_id': segmentation,\n",
    "\t\t'precision_mean': np.mean(metrics[0]),\n",
    "\t\t'precision_std': np.std(metrics[0]),\n",
    "\t\t'recall_mean': np.mean(metrics[1]),\n",
    "\t\t'recall_std': np.std(metrics[1]),\n",
    "\t\t'f1_mean':np.mean( metrics[2]),\n",
    "\t\t'f1_std':np.std( metrics[2]),\n",
    "\t\t'balanced_accuracy_mean': np.mean(metrics[3]),\n",
    "\t\t'balanced_accuracy_std': np.std(metrics[3]),\n",
    "\t\t'specificity_mean': np.mean(metrics[4]),\n",
    "\t\t'specificity_std': np.std(metrics[4]),\n",
    "\t}\n",
    "\tresult += [{**metrics, **best_hyperparams}]\n",
    "\n",
    "\n",
    "pd.DataFrame(result).to_csv(f'./show/{features}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63fb427-5ab3-4b6d-bd19-07aaf2f00d60",
   "metadata": {},
   "source": [
    "#### Without CV XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a441bafc-9aaf-43b2-8afe-1ccac4506ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "def specificity(y_true, y_pred, zero_division=0):\n",
    "\ttn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\tif tn+fp == 0 and zero_division:\n",
    "\t\treturn zero_division\n",
    "\treturn tn / (tn+fp)\n",
    "\n",
    "\n",
    "os.environ['HYPEROPT_FMIN_SEED'] = \"1\"\n",
    "\n",
    "space = {\n",
    "\t'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "\t'gamma': hp.uniform('gamma', 0, 1),\n",
    "\t'reg_alpha' : hp.uniform('reg_alpha', 0, 1),\n",
    "\t'colsample_bytree' : hp.uniform('colsample_bytree', .4, .8),\n",
    "\t'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "\t'n_estimators': 180,\n",
    "\t'seed': 0\n",
    "}\n",
    "\n",
    "result = []\n",
    "dataset = pd.read_csv(FILE)\n",
    "features = r'^unregistered_(discrete_\\d+|ids|mbds|max_values)'\n",
    "result_file = 'unregistered_all'\n",
    "\n",
    "for patient, segmentation in (\n",
    "\tdataset[['patient_id', 'segmentation_id']]\n",
    "\t\t.query('segmentation_id == 5')\n",
    "\t\t.drop_duplicates().to_records(index=False)\n",
    "):\n",
    "\tprint(f'patient - {patient}, segmentation - {segmentation}')\n",
    "\tdataset_group = dataset.query(\n",
    "\t\tf'segmentation_id == {segmentation} and patient_id == {patient}'\n",
    "\t)\n",
    "\ty = dataset_group.label.astype(int).to_numpy()\n",
    "\tX = dataset_group[[name for name in dataset.columns if re.match(features, name)]].to_numpy()\n",
    "\tif patient == 2:\n",
    "\t\tprint(X.shape)\n",
    "\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(\n",
    "\t\tX, y, test_size = 0.3, random_state = 0, stratify=y\n",
    "\t)\n",
    "\t\n",
    "\tneg_class_weight = (y_train == 1).sum() / len(y_train)\n",
    "\tweights = [\n",
    "\t\tneg_class_weight if label == 0 else 1 - neg_class_weight\n",
    "\t\tfor label in y_train\n",
    "\t]\n",
    "\tscaler = MinMaxScaler(feature_range=(0, 1), copy=False)\n",
    "\tscaler = scaler.fit(X_train)\n",
    "\tX_train = scaler.transform(X_train)\n",
    "\tX_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\tdef objective(space):\n",
    "\t\tmodel = xgb.XGBClassifier(\n",
    "\t\t\tuse_label_encoder=False,\n",
    "\t\t\teval_metric='auc',\n",
    "\t\t\tn_estimators=space['n_estimators'],\n",
    "\t\t\tmax_depth=int(space['max_depth']),\n",
    "\t\t\tgamma=space['gamma'],\n",
    "\t\t\treg_alpha=space['reg_alpha'],\n",
    "\t\t\tmin_child_weight=space['min_child_weight'],\n",
    "\t\t\tcolsample_bytree=space['colsample_bytree'],\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tmodel.fit(\n",
    "\t\t\tX_train, y_train,\n",
    "\t\t\tsample_weight=weights,\n",
    "\t\t\teval_set=[( X_train, y_train), ( X_test, y_test)],\n",
    "\t\t\teval_metric=\"auc\",\n",
    "\t\t\tverbose=False,\n",
    "\t\t)\n",
    "\n",
    "\t\tpred = model.predict(X_test)\n",
    "\t\treturn {'loss': -f1_score(y_test, pred), 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "\ttrials = Trials()\n",
    "\n",
    "\tbest_hyperparams = fmin(\n",
    "\t\tfn=objective, space=space, algo=tpe.suggest, max_evals=400, trials=trials\n",
    "\t)\n",
    "\n",
    "\tmodel = xgb.XGBClassifier(\n",
    "\t\tuse_label_encoder=False,\n",
    "\t\teval_metric='auc',\n",
    "\t\tn_estimators=space['n_estimators'],\n",
    "\t\tmax_depth=int(best_hyperparams['max_depth']),\n",
    "\t\tgamma=best_hyperparams['gamma'],\n",
    "\t\treg_alpha=best_hyperparams['reg_alpha'],\n",
    "\t\tmin_child_weight=best_hyperparams['min_child_weight'],\n",
    "\t\tcolsample_bytree=best_hyperparams['colsample_bytree'],\n",
    "\t)\n",
    "\n",
    "\tmodel.fit(\n",
    "\t\tX_train, y_train,\n",
    "\t\tsample_weight=weights,\n",
    "\t\teval_set=[( X_train, y_train), ( X_test, y_test)],\n",
    "\t\teval_metric=\"auc\",\n",
    "\t\tverbose=False,\n",
    "\t)\n",
    "\n",
    "\tpred = model.predict(X_test)\n",
    "\tmetrics = {\n",
    "\t\t'patient_id': patient,\n",
    "\t\t'segmentation_id': segmentation,\n",
    "\t\t'precision': precision_score(y_test, pred),\n",
    "\t\t'recall': recall_score(y_test, pred),\n",
    "\t\t'f1': f1_score(y_test, pred),\n",
    "\t\t'balanced_accuracy': balanced_accuracy_score(y_test, pred),\n",
    "\t\t'specificity': specificity(y_test, pred),\n",
    "\t}\n",
    "\tresult += [{**metrics, **best_hyperparams}]\n",
    "\n",
    "\n",
    "pd.DataFrame(result).to_csv(f'./show/{result_file}_no_cv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183a85ee-43dd-4b7d-98b0-5556eaf891c2",
   "metadata": {},
   "source": [
    "#### Without CV NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3db1241-b1c4-4fa3-aa54-a22f0ef81d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "def specificity(y_true, y_pred, zero_division=0):\n",
    "\ttn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\tif tn+fp == 0 and zero_division:\n",
    "\t\treturn zero_division\n",
    "\treturn tn / (tn+fp)\n",
    "\n",
    "\n",
    "os.environ['HYPEROPT_FMIN_SEED'] = \"1\"\n",
    "\n",
    "space = {\n",
    "\t'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "\t'gamma': hp.uniform('gamma', 0, 1),\n",
    "\t'reg_alpha' : hp.uniform('reg_alpha', 0, 1),\n",
    "\t'colsample_bytree' : hp.uniform('colsample_bytree', .4, .8),\n",
    "\t'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "\t'n_estimators': 180,\n",
    "\t'seed': 0\n",
    "}\n",
    "\n",
    "result = []\n",
    "dataset = pd.read_csv(FILE)\n",
    "features = r'^unregistered_(discrete_\\d+|ids|mbds|max_values)'\n",
    "result_file = 'unregistered_all'\n",
    "\n",
    "for patient, segmentation in (\n",
    "\tdataset[['patient_id', 'segmentation_id']]\n",
    "\t\t.query('segmentation_id == 5')\n",
    "\t\t.drop_duplicates().to_records(index=False)\n",
    "):\n",
    "\tprint(f'patient - {patient}, segmentation - {segmentation}')\n",
    "\tdataset_group = dataset.query(\n",
    "\t\tf'segmentation_id == {segmentation} and patient_id == {patient}'\n",
    "\t)\n",
    "\ty = dataset_group.label.astype(int).to_numpy()\n",
    "\tX = dataset_group[\n",
    "\t\t[name for name in dataset.columns if re.match(features, name)]\n",
    "\t].to_numpy()\n",
    "\tif patient == 2:\n",
    "\t\tprint(X.shape)\n",
    "\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(\n",
    "\t\tX, y, test_size = 0.3, random_state = 0, stratify=y\n",
    "\t)\n",
    "\t\n",
    "\tneg_class_weight = (y_train == 1).sum() / len(y_train)\n",
    "\tweights = [\n",
    "\t\tneg_class_weight if label == 0 else 1 - neg_class_weight\n",
    "\t\tfor label in y_train\n",
    "\t]\n",
    "\tscaler = MinMaxScaler(feature_range=(0, 1), copy=False)\n",
    "\tscaler = scaler.fit(X_train)\n",
    "\tX_train = scaler.transform(X_train)\n",
    "\tX_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\tdef objective(space):\n",
    "\t\tmodel = xgb.XGBClassifier(\n",
    "\t\t\tuse_label_encoder=False,\n",
    "\t\t\teval_metric='auc',\n",
    "\t\t\tn_estimators=space['n_estimators'],\n",
    "\t\t\tmax_depth=int(space['max_depth']),\n",
    "\t\t\tgamma=space['gamma'],\n",
    "\t\t\treg_alpha=space['reg_alpha'],\n",
    "\t\t\tmin_child_weight=space['min_child_weight'],\n",
    "\t\t\tcolsample_bytree=space['colsample_bytree'],\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tmodel.fit(\n",
    "\t\t\tX_train, y_train,\n",
    "\t\t\tsample_weight=weights,\n",
    "\t\t\teval_set=[( X_train, y_train), ( X_test, y_test)],\n",
    "\t\t\teval_metric=\"auc\",\n",
    "\t\t\tverbose=False,\n",
    "\t\t)\n",
    "\n",
    "\t\tpred = model.predict(X_test)\n",
    "\t\treturn {'loss': -f1_score(y_test, pred), 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "\ttrials = Trials()\n",
    "\n",
    "\tbest_hyperparams = fmin(\n",
    "\t\tfn=objective, space=space, algo=tpe.suggest, max_evals=400, trials=trials\n",
    "\t)\n",
    "\n",
    "\tmodel = xgb.XGBClassifier(\n",
    "\t\tuse_label_encoder=False,\n",
    "\t\teval_metric='auc',\n",
    "\t\tn_estimators=space['n_estimators'],\n",
    "\t\tmax_depth=int(best_hyperparams['max_depth']),\n",
    "\t\tgamma=best_hyperparams['gamma'],\n",
    "\t\treg_alpha=best_hyperparams['reg_alpha'],\n",
    "\t\tmin_child_weight=best_hyperparams['min_child_weight'],\n",
    "\t\tcolsample_bytree=best_hyperparams['colsample_bytree'],\n",
    "\t)\n",
    "\n",
    "\tmodel.fit(\n",
    "\t\tX_train, y_train,\n",
    "\t\tsample_weight=weights,\n",
    "\t\teval_set=[( X_train, y_train), ( X_test, y_test)],\n",
    "\t\teval_metric=\"auc\",\n",
    "\t\tverbose=False,\n",
    "\t)\n",
    "\n",
    "\tpred = model.predict(X_test)\n",
    "\tmetrics = {\n",
    "\t\t'patient_id': patient,\n",
    "\t\t'segmentation_id': segmentation,\n",
    "\t\t'precision': precision_score(y_test, pred),\n",
    "\t\t'recall': recall_score(y_test, pred),\n",
    "\t\t'f1': f1_score(y_test, pred),\n",
    "\t\t'balanced_accuracy': balanced_accuracy_score(y_test, pred),\n",
    "\t\t'specificity': specificity(y_test, pred),\n",
    "\t}\n",
    "\tresult += [{**metrics, **best_hyperparams}]\n",
    "\n",
    "\n",
    "pd.DataFrame(result).to_csv(f'./show/{result_file}_no_cv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6e513f-4f83-45d4-8f80-c464dee4db8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learn on each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b58664a-b268-4958-87a9-8a6d8ea85db8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import cmath\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1), copy=False)\n",
    "param_grid = {\n",
    "\t# 'learning_rate': np.linspace(0.000001, 1, 15),\n",
    "\t# 'n_estimators ': list(range(1, 5))\n",
    "\t'reg_alpha': np.linspace(0.000001, 0.1, 15),\n",
    "\t# 'reg_lambda': np.linspace(0.000001, 0.1, 15),\n",
    "}\n",
    "\n",
    "k_folds = StratifiedKFold(n_splits=5)\n",
    "train_n_points = 100\n",
    "FOLDER = 'roc_unregistered'\n",
    "FILE = 'reg_alpha_v1'\n",
    "\n",
    "\n",
    "def get_descrete_points(fd_smooth):\n",
    "\tt_cut = np.linspace(\n",
    "\t\tstart=0,\n",
    "\t\tstop=fd_smooth.data_matrix.shape[1] - 1,\n",
    "\t\tnum=train_n_points, endpoint=True, dtype=int,\n",
    "\t)\n",
    "\treturn fd_smooth.data_matrix[:, t_cut, 0]\n",
    "\n",
    "\n",
    "def get_polar_points(fd_smooth):\n",
    "\tcoefs = np.fft.fft(\n",
    "\t\tfd_smooth.data_matrix\n",
    "\t\t\t.reshape(fd_smooth.data_matrix.shape[0], fd_smooth.data_matrix.shape[1])\n",
    "\t)\n",
    "\treturn (\n",
    "\t\tnp.array([[cmath.polar(coef) for coef in row] for row in coefs])\n",
    "\t\t\t.reshape(coefs.shape[0], -1)\n",
    "\t)\n",
    "\n",
    "\n",
    "def grid_search(Y, X, segmentation_id, patient_id):\n",
    "\tmodel = xgb.XGBClassifier(\n",
    "\t\ttree_method='gpu_hist', eval_metric='logloss', use_label_encoder=False\n",
    "\t)\n",
    "\tsearch_result = GridSearchCV(model, param_grid, scoring='f1').fit(X, Y.ravel())\n",
    "\tgs = pd.DataFrame(search_result.cv_results_['params'])\n",
    "\tgs['segmentation_id'] = segmentation_id\n",
    "\tgs['patient_id'] = patient_id\n",
    "\tgs['mean_test_score'] = search_result.cv_results_[f'mean_test_score']\n",
    "\tgs['std_test_score'] = search_result.cv_results_[f'std_test_score']\n",
    "\tgs = gs.iloc[[search_result.best_index_]]\n",
    "\tif not os.path.exists(f'./{FOLDER}/{FILE}.csv'):\n",
    "\t\tgs.to_csv(f'./{FOLDER}/{FILE}.csv', index=False)\n",
    "\telse:\n",
    "\t\tgs.to_csv(f'./{FOLDER}/{FILE}.csv', index=False, mode='a', header=False)\n",
    "\treturn search_result.best_params_\n",
    "\n",
    "\n",
    "def train_print_rocs(Y, X, segmentation_id, patient_id, reg_alpha):\n",
    "\t# ax = None\n",
    "\t# best_params = grid_search(Y, X, segmentation_id, patient_id)\n",
    "\n",
    "\tfor i, indices in enumerate(k_folds.split(X, Y)):\n",
    "\t\ttrain_index, test_index = indices\n",
    "\t\tX_train, X_test = X[train_index], X[test_index]\n",
    "\t\ty_train, y_test = Y[train_index], Y[test_index]\n",
    "\t\tscaler = MinMaxScaler(feature_range=(0, 1), copy=False)\n",
    "\t\tscaler = scaler.fit(X_train)\n",
    "\t\tX_train = scaler.transform(X_train)\n",
    "\t\tX_test = scaler.transform(X_test)\n",
    "\n",
    "\t\tmodel = xgb.XGBClassifier(\n",
    "\t\t\ttree_method='gpu_hist', eval_metric='logloss', use_label_encoder=False,\n",
    "\t\t\treg_alpha=reg_alpha,\n",
    "\t\t\t# learning_rate=best_params['learning_rate'],\n",
    "\t\t\t# reg_alpha=best_params['reg_alpha'],\n",
    "\t\t\t# reg_lambda=best_params['reg_lambda'],\n",
    "\t\t)\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\tpreds = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\t\tfpr, tpr, thresholds = roc_curve(y_test, preds)\n",
    "\t\troc_scores = pd.DataFrame(\n",
    "\t\t\t{\n",
    "\t\t\t\t'fpr': fpr,\n",
    "\t\t\t\t'tpr': tpr,\n",
    "\t\t\t\t'threshold': thresholds,\n",
    "\t\t\t\t'fold': i,\n",
    "\t\t\t\t'segmentation_id': segmentation_id,\n",
    "\t\t\t\t'patient_id': patient_id,\n",
    "\t\t\t}\n",
    "\t\t)\n",
    "\t\tif not os.path.exists(f'./show/{ROC_FILE}.csv'):\n",
    "\t\t\troc_scores.to_csv(f'./show/{ROC_FILE}.csv', index=False)\n",
    "\t\telse:\n",
    "\t\t\troc_scores.to_csv(f'./show/{ROC_FILE}.csv', index=False, mode='a', header=False)\n",
    "\t\tax = sns.lineplot(x=fpr, y=tpr, ax=ax)\n",
    "\n",
    "\tax.set_ylabel('False positive rate')\n",
    "\tax.set_xlabel('True positive rate')\n",
    "\tplt.savefig(f'./roc_unregistered/xgb_segmentation-{segmentation_id}-patient-{patient_id}.png')\n",
    "\tplt.close()\n",
    "\n",
    "\n",
    "def process_patient(patient, segmentation_id):\n",
    "\tids = ID(patient['fd_smooth']).reshape(-1, 1)\n",
    "\tmbds = MBD(patient['fd_smooth']).reshape(-1, 1)\n",
    "\tmax_values = patient['fd_smooth'].data_matrix.max(axis=1).reshape(-1, 1)\n",
    "\t# descret_points = get_descrete_points(patient['fd_smooth'])\n",
    "\tpolar_points = get_polar_points(patient['fd_smooth'])\n",
    "\n",
    "\ttrain_set = np.hstack([ids, mbds, max_values, polar_points])\n",
    "\tlabels = np.asarray(patient['label']).astype(int).reshape(-1, 1)\n",
    "\t# grid_search(labels, train_set, segmentation_id, patient['patient_id'])\n",
    "\ttrain_print_rocs(labels, train_set, segmentation_id, patient['patient_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8917d96c-1aab-4a99-9a20-832535b5a7d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_roc(Y, X, segmentation_id, patient_id, param):\n",
    "\tpd_roc_scores = []\n",
    "\n",
    "\tfor i, indices in enumerate(k_folds.split(X, Y)):\n",
    "\t\ttrain_index, test_index = indices\n",
    "\t\tX_train, X_test = X[train_index], X[test_index]\n",
    "\t\ty_train, y_test = Y[train_index], Y[test_index]\n",
    "\t\tscaler = MinMaxScaler(feature_range=(0, 1), copy=False)\n",
    "\t\tscaler = scaler.fit(X_train)\n",
    "\t\tX_train = scaler.transform(X_train)\n",
    "\t\tX_test = scaler.transform(X_test)\n",
    "\n",
    "\t\tmodel = xgb.XGBClassifier(\n",
    "\t\t\ttree_method='gpu_hist', eval_metric='logloss', use_label_encoder=False,\n",
    "\t\t\treg_alpha=param,\n",
    "\t\t\t# learning_rate=param,\n",
    "\t\t)\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\tpreds = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\t\tfpr, tpr, thresholds = roc_curve(y_test, preds)\n",
    "\t\tgmean = np.sqrt(tpr * (1 - fpr))\n",
    "\t\tindex = np.argmax(gmean)\n",
    "\t\troc_scores = pd.DataFrame(\n",
    "\t\t\t{\n",
    "\t\t\t\t'fold': [i],\n",
    "\t\t\t\t'gmean': gmean[index],\n",
    "\t\t\t\t'fpr': fpr[index],\n",
    "\t\t\t\t'tpr': tpr[index],\n",
    "\t\t\t\t'threshold': thresholds[index],\n",
    "\t\t\t\t'segmentation_id': segmentation_id,\n",
    "\t\t\t\t'patient_id': patient_id,\n",
    "\t\t\t\t'param': param,\n",
    "\t\t\t\t'f1': f1_score(y_test, preds > thresholds[index])\n",
    "\t\t\t}\n",
    "\t\t)\n",
    "\t\tpd_roc_scores += [roc_scores]\n",
    "\n",
    "\treturn pd_roc_scores\n",
    "\n",
    "\n",
    "def process_patient(patient, segmentation_id):\n",
    "\tids = ID(patient['fd_smooth']).reshape(-1, 1)\n",
    "\tmbds = MBD(patient['fd_smooth']).reshape(-1, 1)\n",
    "\tmax_values = patient['fd_smooth'].data_matrix.max(axis=1).reshape(-1, 1)\n",
    "\t# points = get_polar_points(patient['fd_smooth'])\n",
    "\tpoints = get_descrete_points(patient['fd_smooth'])\n",
    "\n",
    "\ttrain_set = np.hstack([ids, mbds, max_values, points])\n",
    "\tlabels = np.asarray(patient['label']).astype(int).reshape(-1, 1)\n",
    "\tpd_roc_scores = []\n",
    "\t\n",
    "\tfor param in np.linspace(0.000001, 0.1, 15): # reg_alpha\n",
    "\t# for param in np.linspace(0.000001, 1, 15): # lr\n",
    "\t\tpd_roc_scores += train_roc(\n",
    "\t\t\tlabels, train_set, segmentation_id, patient['patient_id'], param\n",
    "\t\t)\n",
    "\tpd_roc_scores = pd.concat(pd_roc_scores)\n",
    "\tpd_roc_scores = (\n",
    "\t\tpd_roc_scores.groupby('fold').f1.max().reset_index().merge(pd_roc_scores)\n",
    "\t\t\t.groupby('fold').gmean.max().reset_index().merge(pd_roc_scores)\n",
    "\t\t\t.groupby('fold').threshold.min().reset_index().merge(pd_roc_scores)\n",
    "\t)\n",
    "\tif not os.path.exists(f'./show/{ROC_FILE}.csv'):\n",
    "\t\tpd_roc_scores.to_csv(f'./show/{ROC_FILE}.csv', index=False)\n",
    "\telse:\n",
    "\t\tpd_roc_scores.to_csv(f'./show/{ROC_FILE}.csv', index=False, mode='a', header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05345c90-4a7a-4073-a368-ad2fdc88316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "# ROC_FILE = 'registered_polar_reg_alpha'\n",
    "# ROC_FILE = 'registered_polar_lr'\n",
    "# ROC_FILE = 'registered_discrete_reg_alpha'\n",
    "ROC_FILE = 'registered_discrete_lr'\n",
    "\n",
    "\n",
    "for segmentation_id in range(0, 25):\n",
    "\tprint(segmentation_id)\n",
    "\tfile = f'./segmentations/segmentation-{segmentation_id}.csv'\n",
    "\tdataset = (\n",
    "\tpd.read_csv(\n",
    "\t\tfile,\n",
    "\t\tdtype={\n",
    "\t\t\t'img_type': int,\n",
    "\t\t\t'patient_id': int,\n",
    "\t\t\t'cycle_id': int,\n",
    "\t\t\t'slice_id': int,\n",
    "\t\t\t'label': bool,\n",
    "\t\t\t'mask_int_mean': float,\n",
    "\t\t\t'segment': int,\n",
    "\t\t},\n",
    "\t)\n",
    "\t.drop_duplicates()\n",
    "\t.sort_values(agg_columns + ['cycle_id'])\n",
    "\t)\n",
    "\tdataset = dataset.merge(dataset.query('label').patient_id.drop_duplicates())\n",
    "\t# dataset = dataset[dataset.patient_id.apply(lambda x: x not in [3, 6, 29, 86, 108, 119, 140])]\n",
    "\tdataset = dataset[dataset.patient_id.apply(lambda x: x in [2, 15, 28, 32, 35, 39, 40, 41, 45, 50, 52, 64, 66])]\n",
    "\tts = (\n",
    "\t\tdataset[['patient_id', 'cycle_id']].drop_duplicates()\n",
    "\t\t\t.groupby('patient_id').cycle_id.count()\n",
    "\t\t\t.apply(lambda x: np.linspace(0, 1, int(x)))\n",
    "\t\t\t.reset_index()\n",
    "\t)\n",
    "\n",
    "\tdataset = dataset.groupby(agg_columns + ['label']).mask_int_mean.apply(list).reset_index()\n",
    "\tbsplined = dataset.groupby('patient_id').mask_int_mean.apply(list).reset_index().merge(ts)\n",
    "\tbsplined = bsplined.apply(\n",
    "\t\tlambda x: smoother.fit_transform(\n",
    "\t\t\tFDataGrid(data_matrix=x['mask_int_mean'], grid_points=x['cycle_id'])\n",
    "\t\t),\n",
    "\t\taxis='columns',\n",
    "\t)\n",
    "\tprint('registering ...')\n",
    "\tbsplined = [get_landmark_registration(fd_smooth, 1) for fd_smooth in bsplined]\n",
    "\t# bsplined = [cut_ends(fd_smooth, 1) for fd_smooth in bsplined]\n",
    "\n",
    "\tdataset = dataset.groupby('patient_id').label.apply(list).reset_index()\n",
    "\tdataset['fd_smooth'] = bsplined\n",
    "\tprocess_patient(dataset.iloc[0], segmentation_id)\n",
    "\tdataset.progress_apply(\n",
    "\t\tprocess_patient,\n",
    "\t\tsegmentation_id=segmentation_id,\n",
    "\t\taxis='columns',\n",
    "\t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d8bed-0c22-495e-a60a-67fd142ae6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "%matplotlib ipympl\n",
    "\n",
    "plt.style.use('dark_background')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781a9c95-fe2c-41b7-ba7f-58ef2511e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.close()\n",
    "\n",
    "metric = 'learning_rate'\n",
    "\n",
    "grid_search = pd.read_csv(f'./roc_unregistered/{metric}.csv')\n",
    "sns.scatterplot(\n",
    "\tdata=grid_search\n",
    "\t\t.groupby('patient_id')\n",
    "\t\t.mean_test_score.max()\n",
    "\t\t.reset_index()\n",
    "\t\t.merge(grid_search),\n",
    "\ty='segmentation_id', x=metric, hue='patient_id',\n",
    "\tpalette=sns.color_palette('tab20')[:13],\n",
    ")\n",
    "plt.savefig(f'./roc_unregistered/{metric}-vs-segmentation.png')\n",
    "plt.close()\n",
    "\n",
    "sns.lineplot(\n",
    "\tdata=grid_search\n",
    "\t\t.groupby(['patient_id', 'segmentation_id'])\n",
    "\t\t.mean_test_score.max()\n",
    "\t\t.reset_index()\n",
    "\t\t.merge(grid_search),\n",
    "\ty='mean_test_score', x='segmentation_id', hue='patient_id',\n",
    "\tpalette=sns.color_palette('tab20')[:13],\n",
    ")\n",
    "plt.savefig(f'./roc_unregistered/{metric}-segmentation.png')\n",
    "plt.close()\n",
    "\n",
    "sns.lineplot(\n",
    "\tdata=grid_search\n",
    "\t\t.groupby(['patient_id', metric])\n",
    "\t\t.mean_test_score.max()\n",
    "\t\t.reset_index()\n",
    "\t\t.merge(grid_search),\n",
    "\ty='mean_test_score', x=metric, hue='patient_id',\n",
    "\tpalette=sns.color_palette('tab20')[:13],\n",
    ")\n",
    "plt.savefig(f'./roc_unregistered/{metric}.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96d6dc2-e5ea-4ab3-877d-84943f167a4d",
   "metadata": {},
   "source": [
    "### T-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae07c0e-ec54-44bd-8736-3a13e91523b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "metric = 'reg_alpha'\n",
    "# metric = 'learning_rate'\n",
    "# folder = 'roc_unregistered'\n",
    "folder = 'roc'\n",
    "suffix = '-paired-registered'\n",
    "# suffix = '-indep'\n",
    "\n",
    "\n",
    "def ttest(sample):\n",
    "\tresults = stats.ttest_rel(sample['x'], sample['y'])\n",
    "\treturn (results.pvalue, results.statistic)\n",
    "\n",
    "\n",
    "grid_search = pd.read_csv(f'./{folder}/{metric}_v0.csv')\n",
    "# grid_search = pd.read_csv(f'./{folder}/{metric}.csv')\n",
    "\n",
    "transformed = (\n",
    "\tgrid_search\n",
    "\t\t.sort_values(['segmentation_id', 'patient_id'])\n",
    "\t\t.groupby('segmentation_id').mean_test_score.apply(list).reset_index()\n",
    "\t\t.assign(join_col=1)\n",
    ")\n",
    "\n",
    "matrix = (\n",
    "\ttransformed.rename(\n",
    "\t\t{'segmentation_id': 'segmentation_x', 'mean_test_score': 'x'}, axis='columns',\n",
    "\t)\n",
    "\t\t.merge(\n",
    "\t\t\ttransformed.rename(\n",
    "\t\t\t\t{'segmentation_id': 'segmentation_y', 'mean_test_score': 'y'},\n",
    "\t\t\t\taxis='columns',\n",
    "\t\t\t)\n",
    "\t\t)\n",
    ")\n",
    "\n",
    "matrix['statistic'] = matrix.apply(ttest, axis='columns')\n",
    "matrix['pvalue'] = [x[0] for x in matrix.statistic]\n",
    "matrix['statistic'] = [x[1] for x in matrix.statistic]\n",
    "matrix = matrix[['segmentation_x', 'segmentation_y', 'statistic', 'pvalue']]\n",
    "(\n",
    "\tmatrix.pivot(index='segmentation_y', columns='segmentation_x', values='pvalue')\n",
    "\t\t.to_csv(f'./show/{metric}-pvalue{suffix}.csv')\n",
    ")\n",
    "(\n",
    "\tmatrix.pivot(index='segmentation_y', columns='segmentation_x', values='statistic')\n",
    "\t\t.to_csv(f'./show/{metric}-statistic{suffix}.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49817f4f-686c-4d29-8f04-d96b61936eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "metric = 'reg_alpha'\n",
    "# metric = 'learning_rate'\n",
    "# folder = 'roc_unregistered'\n",
    "folder = 'roc'\n",
    "suffix = '-paired-registered'\n",
    "# suffix = '-indep'\n",
    "\n",
    "\n",
    "def friedman(data_file):\n",
    "\ttransformed = (\n",
    "\t\tpd.read_csv(data_file)\n",
    "\t\t# pd.read_csv(f'./{folder}/{metric}.csv')\n",
    "\t\t\t.sort_values(['segmentation_id', 'patient_id'])\n",
    "\t\t\t.groupby('segmentation_id').mean_test_score.apply(list).tolist()\n",
    "\t)\n",
    "\n",
    "\treturn stats.friedmanchisquare(*transformed)\n",
    "\n",
    "result = [\n",
    "\t(optimized, registered, with_discrete, friedman(data_file))\n",
    "\tfor data_file, optimized, registered, with_discrete in [\n",
    "\t\t('./roc/learning_rate_v1.csv', 'learning_rate', True, True),\n",
    "\t\t('./roc/learning_rate_both.csv', 'learning_rate', True, False),\n",
    "\t\t('./roc/reg_alpha_v1.csv', 'reg_alpha', True, True),\n",
    "\t\t('./roc/reg_alpha_both.csv', 'reg_alpha', True, False),\n",
    "\t\t\n",
    "\t\t('./roc_unregistered/learning_rate_v1.csv', 'learning_rate', False, True),\n",
    "\t\t('./roc_unregistered/learning_rate_both.csv', 'learning_rate', False, False),\n",
    "\t\t('./roc_unregistered/reg_alpha_v1.csv', 'reg_alpha', False, True),\n",
    "\t\t('./roc_unregistered/reg_alpha_both.csv', 'reg_alpha', False, False),\n",
    "\t]\n",
    "]\n",
    "(\n",
    "\tpd.DataFrame(result, columns=['optimized', 'registered', 'with_discrete', 'statistic'])\n",
    "\t\t.assign(\n",
    "\t\t\tpvalue=lambda y: [x[1] for x in y.statistic],\n",
    "\t\t\tstatistic=lambda y: [x[0] for x in y.statistic],\n",
    "\t\t)\n",
    "\t\t.to_csv('./show/friednman.csv', index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54acea66-0ec0-4b98-8ec1-d844162dfb57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\Aleksas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\scipy\\stats\\morestats.py:3141: UserWarning:Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      " C:\\Users\\Aleksas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\scipy\\stats\\morestats.py:3155: UserWarning:Sample size too small for normal approximation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>statistic</th>\n",
       "      <th>pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.024704e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.757208e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.992823e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.980232e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.979196e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.296899e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.341943e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.027107e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>159.0</td>\n",
       "      <td>9.368029e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>52</td>\n",
       "      <td>98.0</td>\n",
       "      <td>3.546347e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.667683e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>66</td>\n",
       "      <td>127.0</td>\n",
       "      <td>3.525196e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    patient_id  statistic        pvalue\n",
       "0            2        3.5  1.024704e-01\n",
       "1           15       60.0  6.757208e-01\n",
       "2           28       23.0  1.992823e-01\n",
       "3           32        3.0  2.980232e-07\n",
       "4           35       74.0  3.979196e-01\n",
       "5           39       39.0  4.296899e-04\n",
       "6           40        NaN           NaN\n",
       "7           41        5.0  2.341943e-01\n",
       "8           45       46.0  1.027107e-03\n",
       "9           50      159.0  9.368029e-01\n",
       "10          52       98.0  3.546347e-01\n",
       "11          64       23.0  4.667683e-04\n",
       "12          66      127.0  3.525196e-01"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# metric = 'learning_rate'\n",
    "metric = 'reg_alpha'\n",
    "# version = 'both'\n",
    "version = 'v1'\n",
    "\n",
    "\n",
    "def wilcoxon_score(x):\n",
    "\tif x['registered'] == x['unregistered']:\n",
    "\t\treturn None\n",
    "\treturn stats.wilcoxon(x['registered'], x['unregistered'])\n",
    "\n",
    "\n",
    "\n",
    "t_test = (\n",
    "\tpd.read_csv(f'./roc/{metric}_{version}.csv')\n",
    "\t\t.sort_values(['segmentation_id', 'patient_id'])\n",
    "\t\t.groupby('patient_id')\n",
    "\t\t.mean_test_score.apply(list).reset_index()\n",
    "\t\t.rename({'mean_test_score': 'registered'}, axis='columns')\n",
    "\t\t.merge(\n",
    "\t\t\tpd.read_csv(f'./roc_unregistered/{metric}_{version}.csv')\n",
    "\t\t\t.sort_values(['segmentation_id', 'patient_id'])\n",
    "\t\t\t\t.groupby('patient_id')\n",
    "\t\t\t\t.mean_test_score.apply(list).reset_index()\n",
    "\t\t\t\t.rename({'mean_test_score': 'unregistered'}, axis='columns')\n",
    "\t\t)\n",
    "\t\t.assign(statistic=lambda y: y.apply(wilcoxon_score, axis='columns'))\n",
    "\t\t.assign(\n",
    "\t\t\tpvalue=lambda y: [x[1] if x else None for x in y.statistic],\n",
    "\t\t\tstatistic=lambda y: [x[0] if x else None for x in y.statistic],\n",
    "\t\t)\n",
    "\t[['patient_id', 'statistic', 'pvalue']]\n",
    ")\n",
    "\n",
    "t_test.to_csv(f'./show/{metric}-{version}-wilcoxon.csv', index=False, float_format='%.25f')\n",
    "t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed9c5b8b-e171-4a22-b5fb-688e38bf1d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=8295.5, pvalue=5.622979822842875e-13)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metric = 'learning_rate'\n",
    "# metric = 'reg_alpha'\n",
    "version = 'both'\n",
    "\n",
    "stats.wilcoxon(\n",
    "\tpd.read_csv(f'./roc/{metric}_{version}.csv')\n",
    "\t\t.sort_values(['segmentation_id', 'patient_id'])\n",
    "\t\t.mean_test_score\n",
    "\t\t.to_numpy(),\n",
    "\tpd.read_csv(f'./roc_unregistered/{metric}_{version}.csv')\n",
    "\t\t.sort_values(['segmentation_id', 'patient_id'])\n",
    "\t\t.mean_test_score\n",
    "\t\t.to_numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe8321-0068-4b04-a4e0-83125beb9cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for segmentation_id in range(0, 25):\n",
    "\tplt.close()\n",
    "\n",
    "\tmetric = 'learning_rate'\n",
    "\tif not os.path.exists(f'./roc/{metric}'):\n",
    "\t\t  os.makedirs(f'./roc/{metric}')\n",
    "\tgrid_search = pd.read_csv(f'./roc/{metric}.csv')\n",
    "\tsns.scatterplot(\n",
    "\t\tdata=grid_search.query(f'segmentation_id == {segmentation_id}'),\n",
    "\t\ty='mean_test_score', x=metric, hue='patient_id',\n",
    "\t\tpalette=sns.color_palette('tab20')[:13],\n",
    "\t)\n",
    "\tplt.savefig(f'./roc/{metric}/segmentation-{segmentation_id}.png')\n",
    "\n",
    "for segmentation_id in range(0, 25):\n",
    "\tplt.close()\n",
    "\n",
    "\tmetric = 'reg_alpha'\n",
    "\tif not os.path.exists(f'./roc/{metric}'):\n",
    "\t\t  os.makedirs(f'./roc/{metric}')\n",
    "\tgrid_search = pd.read_csv(f'./roc/{metric}.csv')\n",
    "\tsns.scatterplot(\n",
    "\t\tdata=grid_search.query(f'segmentation_id == {segmentation_id}'),\n",
    "\t\ty='mean_test_score', x=metric, hue='patient_id',\n",
    "\t\tpalette=sns.color_palette('tab20')[:13],\n",
    "\t)\n",
    "\tplt.savefig(f'./roc/{metric}/segmentation-{segmentation_id}.png')\n",
    "\n",
    "for segmentation_id in range(0, 25):\n",
    "\tplt.close()\n",
    "\n",
    "\tmetric = 'reg_lambda'\n",
    "\tif not os.path.exists(f'./roc/{metric}'):\n",
    "\t\t  os.makedirs(f'./roc/{metric}')\n",
    "\tgrid_search = pd.read_csv(f'./roc/{metric}.csv')\n",
    "\tsns.scatterplot(\n",
    "\t\tdata=grid_search.query(f'segmentation_id == {segmentation_id}'),\n",
    "\t\ty='mean_test_score', x=metric, hue='patient_id',\n",
    "\t\tpalette=sns.color_palette('tab20')[:13],\n",
    "\t)\n",
    "\tplt.savefig(f'./roc/{metric}/segmentation-{segmentation_id}.png')\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
