{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1518de7b-3328-4bdf-a2db-9272f2a9e664",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import pyperclip\n",
    "import re\n",
    "\n",
    "from skfda import FDataGrid\n",
    "from skfda.representation.basis import BSpline\n",
    "from skfda.preprocessing.smoothing import BasisSmoother\n",
    "from skfda.exploratory.depth import IntegratedDepth, ModifiedBandDepth\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score, roc_curve, confusion_matrix\n",
    "\n",
    "\n",
    "agg_columns = ['patient_id', 'slice_id', 'img_type']\n",
    "features = r'^(discrete_\\d+|ids|mbds|max_values)'\n",
    "\n",
    "n_basis=18\n",
    "order=4\n",
    "\n",
    "prc_rm=0.05\n",
    "n_points =111\n",
    "train_n_points = 100\n",
    "\n",
    "basis = BSpline(domain_range=(0, 1), n_basis=n_basis, order=order)\n",
    "smoother = BasisSmoother(basis=basis, return_basis=True, method='svd')\n",
    "ID = IntegratedDepth()\n",
    "MBD = ModifiedBandDepth()\n",
    "k_folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "\n",
    "def cut_ends(bsplined, order=0, prc_rm_start=prc_rm, prc_rm_end=prc_rm, n_points=n_points):\n",
    "\tbsplined_grid = bsplined.derivative(order=order).to_grid(np.linspace(0, 1, n_points))\n",
    "\treturn FDataGrid(\n",
    "\t\tdata_matrix=bsplined_grid.data_matrix[\n",
    "\t\t\t..., int(n_points * prc_rm_start): int(n_points * (1 - prc_rm_end)), 0\n",
    "\t\t],\n",
    "\t\tgrid_points=bsplined_grid.grid_points[0][\n",
    "\t\t\tint(n_points * prc_rm_start): int(n_points * (1 - prc_rm_end))\n",
    "\t\t]\n",
    "\t)\n",
    "\n",
    "\n",
    "def specificity(y_true, y_pred, zero_division=0):\n",
    "\ttn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\tif tn+fp == 0 and zero_division:\n",
    "\t\treturn zero_division\n",
    "\treturn tn / (tn+fp)\n",
    "\n",
    "\n",
    "def get_descrete_points(fd_smooth):\n",
    "\tt_cut = np.linspace(\n",
    "\t\tstart=0,\n",
    "\t\tstop=fd_smooth.data_matrix.shape[1] - 1,\n",
    "\t\tnum=train_n_points, endpoint=True, dtype=int,\n",
    "\t)\n",
    "\treturn fd_smooth.data_matrix[:, t_cut, 0]\n",
    "\n",
    "\n",
    "def extract_features(prefix='peripheral'):\n",
    "\tsegmentations = []\n",
    "\n",
    "\tfor segmentation_id in tqdm(range(0, 25)):\n",
    "\t\tfile = f'./segmentations/{prefix}-{segmentation_id}.csv'\n",
    "\t\tdataset = (\n",
    "\t\tpd.read_csv(\n",
    "\t\t\tfile,\n",
    "\t\t\tdtype={\n",
    "\t\t\t\t'img_type': int,\n",
    "\t\t\t\t'patient_id': int,\n",
    "\t\t\t\t'cycle_id': int,\n",
    "\t\t\t\t'slice_id': int,\n",
    "\t\t\t\t'label': bool,\n",
    "\t\t\t\t'mask_int_mean': float,\n",
    "\t\t\t\t'segment': int,\n",
    "\t\t\t},\n",
    "\t\t)\n",
    "\t\t.drop_duplicates()\n",
    "\t\t.sort_values(agg_columns + ['cycle_id'])\n",
    "\t\t)\n",
    "\t\tts = (\n",
    "\t\t\tdataset[['patient_id', 'cycle_id']].drop_duplicates()\n",
    "\t\t\t\t.groupby('patient_id').cycle_id.count()\n",
    "\t\t\t\t.apply(lambda x: np.linspace(0, 1, int(x)))\n",
    "\t\t\t\t.reset_index()\n",
    "\t\t)\n",
    "\n",
    "\t\tdataset = dataset.groupby(agg_columns + ['label']).mask_int_mean.apply(list).reset_index()\n",
    "\t\tbsplined = dataset.groupby('patient_id').mask_int_mean.apply(list).reset_index().merge(ts)\n",
    "\t\tbsplined = bsplined.apply(\n",
    "\t\t\tlambda x: smoother.fit_transform(\n",
    "\t\t\t\tFDataGrid(data_matrix=x['mask_int_mean'], grid_points=x['cycle_id'])\n",
    "\t\t\t),\n",
    "\t\t\taxis='columns',\n",
    "\t\t)\n",
    "\t\tunregistered = [cut_ends(fd_smooth, 1) for fd_smooth in bsplined]\n",
    "\n",
    "\t\tdataset['ids'] = np.concatenate(\n",
    "\t\t\t[ID(fd_smooth).reshape(-1, 1) for fd_smooth in unregistered]\n",
    "\t\t)\n",
    "\t\tdataset['mbds'] = np.concatenate(\n",
    "\t\t\t[MBD(fd_smooth).reshape(-1, 1) for fd_smooth in unregistered]\n",
    "\t\t)\n",
    "\t\tdataset['max_values'] = np.concatenate(\n",
    "\t\t\t[fd_smooth.data_matrix.max(axis=1).reshape(-1, 1) for fd_smooth in unregistered]\n",
    "\t\t)\n",
    "\n",
    "\t\tunregistered = [get_descrete_points(fd_smooth) for fd_smooth in unregistered]\n",
    "\n",
    "\t\tsegmentations += [\n",
    "\t\t\tdataset.drop('mask_int_mean', axis='columns')\n",
    "\t\t\t\t.assign(segmentation_id=segmentation_id)\n",
    "\t\t\t\t.join(\n",
    "\t\t\t\t\tpd.DataFrame(np.concatenate(unregistered), columns=[f'discrete_{i}' for i in range(100)])\n",
    "\t\t\t\t)\n",
    "\t\t]\n",
    "\treturn pd.concat(segmentations)\n",
    "\n",
    "\n",
    "def train_fold(segmentation_id, X, Y, indices):\n",
    "\ttrain_indices, test_indices = indices\n",
    "\tX_train, X_test = X[train_indices], X[test_indices]\n",
    "\ty_train, y_test = Y[train_indices], Y[test_indices]\n",
    "\n",
    "\tscaler = MinMaxScaler(feature_range=(0, 1), copy=False)\n",
    "\tscaler = scaler.fit(X_train)\n",
    "\tX_train = scaler.transform(X_train)\n",
    "\tX_test = scaler.transform(X_test)\n",
    "\tlabels = dataset['label']\n",
    "\tneg_class_weight = (y_train == 1).sum() / len(y_train)\n",
    "\tweights = [neg_class_weight if label == 0 else 1 - neg_class_weight for label in y_train]\n",
    "\n",
    "\tscaler = MinMaxScaler(feature_range=(0, 1), copy=False)\n",
    "\tscaler = scaler.fit(X_train)\n",
    "\tX_train = scaler.transform(X_train)\n",
    "\tX_test = scaler.transform(X_test)\n",
    "\n",
    "\tmodel = xgb.XGBClassifier(tree_method='gpu_hist', eval_metric='logloss', use_label_encoder=False)\n",
    "\tmodel.fit(\n",
    "\t\tX_train, y_train,\n",
    "\t\tsample_weight=[neg_class_weight if label == 0 else 1 - neg_class_weight for label in y_train],\n",
    "\t\teval_set=[( X_train, y_train), ( X_test, y_test)],\n",
    "\t\tverbose=False,\n",
    "\t)\n",
    "\n",
    "\tpred = model.predict(X_test)\n",
    "\treturn {\n",
    "\t\t'segmentation_id': segmentation_id,\n",
    "\t\t'precision': precision_score(y_test, pred, zero_division=0),\n",
    "\t\t'recall': recall_score(y_test, pred, zero_division=0),\n",
    "\t\t'f1': f1_score(y_test, pred, zero_division=0),\n",
    "\t\t'balanced_accuracy': balanced_accuracy_score(y_test, pred),\n",
    "\t\t'specificity': specificity(y_test, pred, zero_division=0),\n",
    "\t}\n",
    "\n",
    "\n",
    "\n",
    "def train_model(dataset):\n",
    "\tY = dataset.label.astype(int).to_numpy()\n",
    "\tX = dataset[[name for name in dataset.columns if re.match(features, name)]].to_numpy()\n",
    "\tsegmentation_id = dataset['segmentation_id'].tolist()[0]\n",
    "\treturn [train_fold(segmentation_id, X, Y, indices) for indices in k_folds.split(X, Y)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc2f77d-c721-417f-8535-c8a1efadcb4b",
   "metadata": {},
   "source": [
    "## Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f4b40-66ee-4ff8-bcbb-21443c6f9b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features('peripheral').to_csv('peripheral.csv')\n",
    "extract_features('transitional').to_csv('transitional.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30b897-4887-4d55-a896-aceb990e9d9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a4f83-d411-404b-b92c-6bca7c4366c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('transitional.csv')\n",
    "result = pd.concat(\n",
    "\t[\n",
    "\t\tpd.DataFrame.from_records(train_model(dataset.query('segmentation_id == @segmentation_id')))\n",
    "\t\t\t.mean()\n",
    "\t\t\t.to_frame()\n",
    "\t\t\t.transpose()\n",
    "\t\tfor segmentation_id in tqdm(range(0, 25), position=0, leave=True)\n",
    "\t]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac93a15-09aa-4f06-8bbe-4c01e35b708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./show/peripheral_transitional/transitional.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55922ee2-1faf-4c37-8739-6f2ccc454362",
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_metrics = pd.read_csv('./show/peripheral_transitional/transitional.csv')\n",
    "tz_metrics.columns = ['tz_' + col if col != 'segmentation_id' else col for col in tz_metrics.columns]\n",
    "\n",
    "pz_metrics = pd.read_csv('./show/peripheral_transitional/peripheral.csv')\n",
    "pz_metrics.columns = ['pz_' + col if col != 'segmentation_id' else col for col in pz_metrics.columns]\n",
    "\n",
    "tz_metrics.merge(pz_metrics).iloc[:,[0, 1, 6, 2, 7, 3, 8, 4, 9, 5, 10]].to_csv('./show/peripheral_transitional/peripheral_transitional.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
